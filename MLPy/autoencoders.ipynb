{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryamanpandya99/AIFundamentals/blob/master/MLPy/autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-m2-9v6kcbh"
      },
      "source": [
        "# Autoencoders\n",
        "\n",
        "By Definition, an autoencoder is a neural network trained to downsize then reconstruct its input data from a latent representation. A convolutional autoencoder uses a CNN encoder to compress the input into the a latent representation and a deconvolutional (transposed convolution) decoder to reconstruct the input from the latent representation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDHWFdpKk0py",
        "outputId": "8adf15bd-fadc-42d4-f0b6-c8075e92fb06"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Lw9HK4qk72d"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "ppJ9ovuukcbm"
      },
      "outputs": [],
      "source": [
        "import pickle, gzip, math, os, time, shutil, torch, matplotlib.pyplot as plt, numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "l0EqXUj-kcbn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pathlib as Path\n",
        "from torch.utils.data import DataLoader, default_collate, Dataset\n",
        "from typing import Mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "HOyrxuLYkcbn"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/data/cifar-10-batches-py/data_batch_1', 'rb') as f:\n",
        "    dataset_dict = pickle.load(f, encoding='bytes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu_xJl9tkcbo",
        "outputId": "3637e95d-6586-486b-940b-0a5376b536c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([b'batch_label', b'labels', b'data', b'filenames'])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "dataset_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJYVMYf9kcbo",
        "outputId": "2b6c4e59-46ad-4079-a9e1-2ccdf1bb384b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3072,)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "dataset_dict[b'data'][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZWxvZK4kcbp",
        "outputId": "acca26a3-0d0f-412c-91cb-b0b10465eba0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'training batch 1 of 5'"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "dataset_dict[b'batch_label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhJ2kzEwkcbq",
        "outputId": "d5acbfe1-9791-4b7e-d16c-4521d244aa46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "dataset_dict[b'labels'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcehUJ6Ekcbq",
        "outputId": "78f23848-fbf5-4f58-e8c7-ccad2d96a048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: torch.Size([8000, 3, 32, 32])\n",
            "Training labels shape: torch.Size([8000])\n",
            "Validation data shape: torch.Size([2000, 3, 32, 32])\n",
            "Validation labels shape: torch.Size([2000])\n"
          ]
        }
      ],
      "source": [
        "data = dataset_dict[b'data']\n",
        "labels = dataset_dict[b'labels']\n",
        "\n",
        "data = torch.tensor(data, dtype=torch.float32).view(-1, 3, 32, 32)\n",
        "labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "split_idx = int(0.8 * len(data))\n",
        "\n",
        "x_train, x_valid = data[:split_idx], data[split_idx:]\n",
        "y_train, y_valid = labels[:split_idx], labels[split_idx:]\n",
        "\n",
        "print(\"Training data shape:\", x_train.shape)\n",
        "print(\"Training labels shape:\", y_train.shape)\n",
        "\n",
        "print(\"Validation data shape:\", x_valid.shape)\n",
        "print(\"Validation labels shape:\", y_valid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGGXFZY9kcbr",
        "outputId": "7a5cf336-0df1-4740-d344-dba3a9e62122"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1964,  0.7119, -0.0843,  0.0830, -0.1124,  0.0531,  0.0208, -0.1821,\n",
              "          0.6108, -0.1611]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "# sample cnn\n",
        "from torch import nn\n",
        "\n",
        "simple_cnn = nn.Sequential(\n",
        "    nn.Conv2d(3, 4, kernel_size=3, stride=2, padding=1),    # 14x14x4\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(4, 8, kernel_size=3, stride=2, padding=1),    # 7x7x8\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),    # 4x4x16\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),    # 2x2x16\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),    # 1x1x10\n",
        "    nn.Flatten(),\n",
        ")\n",
        "\n",
        "simple_cnn(x_train[0].unsqueeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "3UsYc0ugkcbr"
      },
      "outputs": [],
      "source": [
        "X = x_train.reshape(8000, 3, 32, 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3C4LAFkkcbr",
        "outputId": "81b05f3e-908f-44a7-ec72-8fe7dc9a0737"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8000, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "jytjAN-Akcbr"
      },
      "outputs": [],
      "source": [
        "def show_torch_image(img):\n",
        "    img = img.permute(1, 2, 0)\n",
        "    img = img.numpy().astype(np.uint8)\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "zg5oytl_kcbs",
        "outputId": "da850771-ce91-4237-8323-fe3cf8a11c51"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "show_torch_image(X[13])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "PIvCLjmmkcbs"
      },
      "outputs": [],
      "source": [
        "class ConvolutionalAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 4, kernel_size=3, stride=2, padding=1),    # 16x16x4\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(4, 8, kernel_size=3, stride=2, padding=1),    # 8x8x8\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),    # 4x4x16\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),    # 2x2x16\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.decoder_part_1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(16, 16, kernel_size=3, stride=2, padding=1, output_padding=1),    # 4x4x16\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.decoder_part_2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1),    # 8x8x8\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.decoder_part_3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(8, 4, kernel_size=3, stride=2, padding=1, output_padding=1),    # 16x16x4\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(4, 3, kernel_size=3, stride=2, padding=1, output_padding=1),    # 32x32x3\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder_part_1(encoded)\n",
        "        # print(f\"decoder_1 output shape: {decoded.shape}\")\n",
        "        decoded = self.decoder_part_2(decoded)\n",
        "        # print(f\"decoder_2 output shape: {decoded.shape}\")\n",
        "        decoded = self.decoder_part_3(decoded)\n",
        "        # print(f\"decoder_3 output shape: {decoded.shape}\")\n",
        "        return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "TUnlsePakcbs"
      },
      "outputs": [],
      "source": [
        "def validate(model, loss_func, valid_dl):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        tot_loss,count = 0.,0\n",
        "        for xb,_ in valid_dl:\n",
        "            pred = model(xb)\n",
        "            n = len(xb)\n",
        "            count += n\n",
        "            tot_loss += loss_func(pred,xb).item()*n\n",
        "    return tot_loss/count\n",
        "\n",
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        model.train()\n",
        "        for xb,yb in train_dl:\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, xb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "\n",
        "        tot_loss_count = validate(model, loss_func, valid_dl)\n",
        "        print(f\"Validation loss: {tot_loss_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "vtzoZs_qkcbs"
      },
      "outputs": [],
      "source": [
        "class CIFARCustomDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "chPrqHGrkcbs"
      },
      "outputs": [],
      "source": [
        "train_ds = CIFARCustomDataset(x_train, y_train)\n",
        "valid_ds = CIFARCustomDataset(x_valid, y_valid)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BwgBY9Tkcbs",
        "outputId": "aa8c0a86-9b8d-4ff2-e63b-9c3a746ff11b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8000\n"
          ]
        }
      ],
      "source": [
        "print(len(train_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeBLBIyPkcbt",
        "outputId": "4f44f696-e566-4074-a202-869ca939bc21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 32, 32])\n",
            "torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "print(next(iter(train_dl))[0].shape)\n",
        "print(next(iter(train_dl))[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvolutionalAutoencoder()\n",
        "loss_func = nn.MSELoss()\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "ZeQ8wohmlr23"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ba_5Yplkcbt",
        "outputId": "fc272106-c8a9-4d22-c42d-a01359be342c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Validation loss: 18982.155671875\n",
            "Epoch 2/10\n",
            "Validation loss: 18982.154625\n",
            "Epoch 3/10\n",
            "Validation loss: 18982.154234375\n",
            "Epoch 4/10\n",
            "Validation loss: 18982.154125\n",
            "Epoch 5/10\n",
            "Validation loss: 18982.1542578125\n",
            "Epoch 6/10\n",
            "Validation loss: 18982.1541328125\n",
            "Epoch 7/10\n",
            "Validation loss: 18982.15415625\n",
            "Epoch 8/10\n",
            "Validation loss: 18982.15409375\n",
            "Epoch 9/10\n",
            "Validation loss: 18982.1539375\n",
            "Epoch 10/10\n",
            "Validation loss: 18982.154\n"
          ]
        }
      ],
      "source": [
        "fit(10, model, loss_func, opt, train_dl, valid_dl)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7YunZ90lluJM"
      },
      "execution_count": 122,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cv_project",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}